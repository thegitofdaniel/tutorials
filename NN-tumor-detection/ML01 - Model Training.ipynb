{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58193885-781d-46c0-8e70-6327b30f81fd",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e43ac6-04ff-4f9b-91b9-61406ca993d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import AveragePooling2D, Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# general\n",
    "import argparse\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from imutils import paths\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18b80c-a40d-48f6-8bca-1d62788f43d9",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "This data was pre-processed in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "715d18d1-a5da-4972-adf1-837c75c3a59a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4574\n",
      "4574\n",
      "ok - load data\n",
      "[0. 1.]\n",
      "X shape: (4574, 224, 224, 3)\n",
      "Y shape: (4574, 2)\n",
      "ok - processing\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "images = np.load('images.npz')\n",
    "images = images[\"arr_0\"]\n",
    "print(len(images))\n",
    "\n",
    "labels = np.load('labels.npz')\n",
    "labels = labels[\"arr_0\"]\n",
    "print(len(labels))\n",
    "print(\"ok - load data\")\n",
    "\n",
    "# process\n",
    "# one-hot encoding\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "print(labels[0])\n",
    "\n",
    "print(\"X shape:\", images.shape)\n",
    "print(\"Y shape:\", labels.shape)\n",
    "print(\"ok - processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368326f1-5f43-4517-8d6b-3912c55bf699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have too much data for an ordinary CPU computer; so, we will downsize\n",
    "images, test_X, labels, test_Y = train_test_split(images, labels, test_size=0.90, random_state=42, stratify=labels)\n",
    "del test_X\n",
    "del test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bcc992-5336-4abb-9024-28b9a4a27e83",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "We split the *full* dataset into *train*, *validation*, and *test*. The *test* set (i.e. out-of-sample) is randomly extracted from the full dataset without any statistical control. The *train* and *validation* sets are separated using the y variable as a stractifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f48edd-56fa-4cc8-a450-56a7dc2001f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset:\n",
      "Size (p+n): 457\n",
      "Imbalance (p/n): 1.1866028\n",
      "ok - split 1\n"
     ]
    }
   ],
   "source": [
    "# slighlty imabalanced dataset\n",
    "print(\"Full dataset:\")\n",
    "print(\"Size (p+n):\", len(labels))\n",
    "print(\"Imbalance (p/n):\", labels.sum(axis=0)[1]/labels.sum(axis=0)[0])\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(images, labels, test_size=0.05, random_state=42)\n",
    "print(\"ok - split 1\")\n",
    "\n",
    "# open memory space\n",
    "del images\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee09eba9-652f-4090-a844-668c219d8275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok - split 2\n",
      "\n",
      "Train:\n",
      "Size (p+n): 381\n",
      "Imbalance (p/n): 1.1525424\n",
      "\n",
      "Val:\n",
      "Size (p+n): 53\n",
      "Imbalance (p/n): 1.12\n",
      "\n",
      "Test:\n",
      "Size (p+n): 23\n",
      "Imbalance (p/n): 2.2857144\n"
     ]
    }
   ],
   "source": [
    "train_X, val_X, train_Y, val_Y = train_test_split(train_X, train_Y, test_size=0.12, random_state=42, stratify=train_Y)\n",
    "print(\"ok - split 2\")\n",
    "\n",
    "print(\"\\nTrain:\")\n",
    "print(\"Size (p+n):\", len(train_Y))\n",
    "print(\"Imbalance (p/n):\", train_Y.sum(axis=0)[1]/train_Y.sum(axis=0)[0])\n",
    "\n",
    "print(\"\\nVal:\")\n",
    "print(\"Size (p+n):\", len(val_Y))\n",
    "print(\"Imbalance (p/n):\", val_Y.sum(axis=0)[1]/val_Y.sum(axis=0)[0])\n",
    "\n",
    "print(\"\\nTest:\")\n",
    "print(\"Size (p+n):\", len(test_Y))\n",
    "print(\"Imbalance (p/n):\", test_Y.sum(axis=0)[1]/test_Y.sum(axis=0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9edb46b4-a6bf-43bc-aac9-c150c1352d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8336980306345733\n",
      "Val: 0.11597374179431072\n",
      "Test: 0.05032822757111598\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", len(train_Y)/(len(train_Y)+len(val_Y)+len(test_Y)))\n",
    "print(\"Val:\", len(val_Y)/(len(train_Y)+len(val_Y)+len(test_Y)))\n",
    "print(\"Test:\", len(test_Y)/(len(train_Y)+len(val_Y)+len(test_Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed833b-3e63-4b94-80f7-39632ebcf097",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251d3dd-ab04-4a25-9b4f-9f8d7d3ae6f7",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "## Design the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a846318-3e7a-440a-9677-0047577d0168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok - train generator\n",
      "ok - model architecture\n",
      "ok - layers\n",
      "ok - compilation\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 1, 1, 512)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,747,650\n",
      "Trainable params: 32,962\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "ok - summary\n"
     ]
    }
   ],
   "source": [
    "# Build the Image Data Generator\n",
    "train_generator = ImageDataGenerator(fill_mode='nearest', rotation_range=15)\n",
    "print(\"ok - train generator\")\n",
    "\n",
    "# create the architecture\n",
    "base_model = VGG16(weights= 'imagenet', input_tensor= Input(shape = (224, 224, 3)), include_top= False)\n",
    "base_input = base_model.input\n",
    "base_output = base_model.output\n",
    "base_output = AveragePooling2D(pool_size=(4, 4))(base_output)\n",
    "base_output = Flatten(name=\"flatten\")(base_output)\n",
    "base_output = Dense(64, activation=\"relu\")(base_output)\n",
    "base_output = Dropout(0.5)(base_output)\n",
    "base_output = Dense(2, activation=\"softmax\")(base_output)\n",
    "print(\"ok - model architecture\")\n",
    "\n",
    "# freeze the layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "print(\"ok - layers\")\n",
    "    \n",
    "# compile the model\n",
    "model = Model(inputs = base_input, outputs = base_output)\n",
    "\n",
    "model.compile(optimizer=\"adam\"\n",
    "              , metrics= ['accuracy']\n",
    "              , loss= 'binary_crossentropy'\n",
    "             )\n",
    "print(\"ok - compilation\")\n",
    "\n",
    "# summary\n",
    "model.summary()\n",
    "print(\"ok - summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef68d1f-a057-440a-9ad6-d95b19691e77",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e625f893-8d3c-4b63-9588-886697984cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 111s 2s/step - loss: 0.7080 - accuracy: 0.5362 - val_loss: 0.6475 - val_accuracy: 0.6038\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 112s 2s/step - loss: 0.6452 - accuracy: 0.6515 - val_loss: 0.6060 - val_accuracy: 0.7358\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 113s 2s/step - loss: 0.6070 - accuracy: 0.6997 - val_loss: 0.5829 - val_accuracy: 0.7925\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 122s 3s/step - loss: 0.5827 - accuracy: 0.7265 - val_loss: 0.5436 - val_accuracy: 0.8113\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 141s 3s/step - loss: 0.5550 - accuracy: 0.7453 - val_loss: 0.5178 - val_accuracy: 0.8113\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 175s 4s/step - loss: 0.5421 - accuracy: 0.7587 - val_loss: 0.4884 - val_accuracy: 0.8491\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 137s 3s/step - loss: 0.5216 - accuracy: 0.7553 - val_loss: 0.4826 - val_accuracy: 0.7925\n"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "batch_size = 8\n",
    "train_steps = len(train_X) // batch_size\n",
    "validation_steps = len(val_X) // batch_size\n",
    "epochs = 10\n",
    "\n",
    "# early stop\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
    "callbacks = [earlystop_callback]\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(train_generator.flow(train_X, train_Y, batch_size=batch_size)\n",
    "                    , steps_per_epoch=train_steps\n",
    "                    , validation_data=(val_X, val_Y)\n",
    "                    , validation_steps=validation_steps\n",
    "                    , epochs=epochs\n",
    "                    , callbacks=callbacks\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba002603-89f6-4c87-8f9c-6639ef1234f7",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "## Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dd8a0ce-9264-4ede-98cf-387c60a362cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81        25\n",
      "           1       0.90      0.68      0.78        28\n",
      "\n",
      "    accuracy                           0.79        53\n",
      "   macro avg       0.81      0.80      0.79        53\n",
      "weighted avg       0.82      0.79      0.79        53\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (7,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mggplot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, N), history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m label\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, N), history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     17\u001b[0m label\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2758\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2759\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (7,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARq0lEQVR4nO3cb2iV9f/H8ddxR4U53ddzjm4OR9FBb5Sg2UF0Qbg82I2oRNAbYt0YEbnSWdRqS1Op4UH8R/4hqTGSujEilDBSOI6wNoSZTlMhNyfk2JFxzskcW6vN6/rd+Nq52lf9XaeznR3b5/m4d3E+2/X2rT6Z19zx2LZtCwAw7k3I9QAAgLFB8AHAEAQfAAxB8AHAEAQfAAxB8AHAEF63AwcPHtTZs2dVWFioXbt23fW6bdtqaGjQuXPnNHnyZFVWVuqRRx7JyrAAgMy5foW/dOlS1dbW3vf1c+fO6caNG/roo4/0yiuv6NNPPx3VAQEAo8M1+I8++qgKCgru+/qZM2f01FNPyePxaO7cuerr69Ovv/46qkMCAEbO9ZGOm2QyqUAgkLr2+/1KJpOaPn36XWej0aii0agkKRKJjPTWAIB/YMTB/yfC4bDC4XDquru7eyxv/8AKBAKKx+O5HuOBwC4c7MLBLhwlJSUZf+yI/5eOz+cb9huRSCTk8/lG+mkBAKNsxMEPhUI6deqUbNvWlStXlJ+ff8/HOQCA3HJ9pLN3715dvnxZvb29evXVV7V69WoNDQ1JkpYvX67HH39cZ8+e1YYNGzRp0iRVVlZmfWgAwD/nGvyNGzf+v697PB69/PLLozUPACBL+ElbADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADAEwQcAQxB8ADCEN51DbW1tamhokGVZWrZsmVasWDHs9Xg8rgMHDqivr0+WZWnNmjVauHBhNuYFAGTINfiWZam+vl6bNm2S3+9XTU2NQqGQZs+enTrz1VdfacmSJVq+fLm6urq0fft2gg8ADxjXRzodHR0qLi5WUVGRvF6vysrK1NraOuyMx+NRf3+/JKm/v1/Tp0/PzrQAgIy5foWfTCbl9/tT136/X+3t7cPOrFq1Sh9++KGOHz+uP/74Q5s3b77n54pGo4pGo5KkSCSiQCAwktnHDa/Xyy7uYBcOduFgF6MjrWf4bpqbm7V06VI999xzunLlivbt26ddu3ZpwoTh/4AIh8MKh8Op63g8Phq3/9cLBALs4g524WAXDnbhKCkpyfhjXR/p+Hw+JRKJ1HUikZDP5xt2pqmpSUuWLJEkzZ07V4ODg+rt7c14KADA6HMNfjAYVCwWU09Pj4aGhtTS0qJQKDTsTCAQ0MWLFyVJXV1dGhwc1LRp07IzMQAgI66PdPLy8lRRUaG6ujpZlqXy8nKVlpaqsbFRwWBQoVBIL730kg4dOqRvvvlGklRZWSmPx5P14QEA6fPYtm3n6ubd3d25uvUDheeTDnbhYBcOduHI6jN8AMD4QPABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBDedA61tbWpoaFBlmVp2bJlWrFixV1nWlpa9OWXX8rj8eihhx5SVVXVaM8KABgB1+BblqX6+npt2rRJfr9fNTU1CoVCmj17dupMLBbT0aNH9cEHH6igoEC//fZbVocGAPxzro90Ojo6VFxcrKKiInm9XpWVlam1tXXYmZMnT+qZZ55RQUGBJKmwsDA70wIAMub6FX4ymZTf709d+/1+tbe3DzvT3d0tSdq8ebMsy9KqVau0YMGCuz5XNBpVNBqVJEUiEQUCgZHMPm54vV52cQe7cLALB7sYHWk9w3djWZZisZi2bNmiZDKpLVu2aOfOnZoyZcqwc+FwWOFwOHUdj8dH4/b/eoFAgF3cwS4c7MLBLhwlJSUZf6zrIx2fz6dEIpG6TiQS8vl8d50JhULyer2aOXOmZs2apVgslvFQAIDR5xr8YDCoWCymnp4eDQ0NqaWlRaFQaNiZRYsW6dKlS5KkW7duKRaLqaioKDsTAwAy4vpIJy8vTxUVFaqrq5NlWSovL1dpaakaGxsVDAYVCoU0f/58nT9/Xm+88YYmTJigtWvXaurUqWMxPwAgTR7btu1c3fyvb/aajueTDnbhYBcOduHI6jN8AMD4QPABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMkVbw29raVFVVpfXr1+vo0aP3PXf69GmtXr1aV69eHa35AACjxDX4lmWpvr5etbW12rNnj5qbm9XV1XXXud9//13ffvut5syZk5VBAQAj4xr8jo4OFRcXq6ioSF6vV2VlZWptbb3rXGNjo1544QVNnDgxK4MCAEbG63YgmUzK7/enrv1+v9rb24ed6ezsVDwe18KFC/X111/f93NFo1FFo1FJUiQSUSAQyHTuccXr9bKLO9iFg1042MXocA2+G8uydPjwYVVWVrqeDYfDCofDqet4PD7S248LgUCAXdzBLhzswsEuHCUlJRl/rGvwfT6fEolE6jqRSMjn86WuBwYGdP36dW3btk2SdPPmTe3YsUPV1dUKBoMZDwYAGF2uwQ8Gg4rFYurp6ZHP51NLS4s2bNiQej0/P1/19fWp661bt+rFF18k9gDwgHENfl5enioqKlRXVyfLslReXq7S0lI1NjYqGAwqFAqNxZwAgBHy2LZt5+rm3d3dubr1A4Xnkw524WAXDnbhGMkzfH7SFgAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBAEHwAMQfABwBDedA61tbWpoaFBlmVp2bJlWrFixbDXjx07ppMnTyovL0/Tpk3TunXrNGPGjGzMCwDIkOtX+JZlqb6+XrW1tdqzZ4+am5vV1dU17MzDDz+sSCSinTt3avHixfr888+zNjAAIDOuwe/o6FBxcbGKiork9XpVVlam1tbWYWfmzZunyZMnS5LmzJmjZDKZnWkBABlzfaSTTCbl9/tT136/X+3t7fc939TUpAULFtzztWg0qmg0KkmKRCIKBAL/cNzxyev1sos72IWDXTjYxehI6xl+uk6dOqXOzk5t3br1nq+Hw2GFw+HUdTweH83b/2sFAgF2cQe7cLALB7twlJSUZPyxro90fD6fEolE6jqRSMjn89117sKFCzpy5Iiqq6s1ceLEjAcCAGSHa/CDwaBisZh6eno0NDSklpYWhUKhYWeuXbumTz75RNXV1SosLMzasACAzLk+0snLy1NFRYXq6upkWZbKy8tVWlqqxsZGBYNBhUIhff755xoYGNDu3bsl/fefX++8807WhwcApM9j27adq5t3d3fn6tYPFJ5POtiFg1042IUjq8/wAQDjA8EHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwBMEHAEMQfAAwhDedQ21tbWpoaJBlWVq2bJlWrFgx7PXBwUHt379fnZ2dmjp1qjZu3KiZM2dmY14AQIZcv8K3LEv19fWqra3Vnj171NzcrK6urmFnmpqaNGXKFO3bt0/PPvusvvjii6wNDADIjGvwOzo6VFxcrKKiInm9XpWVlam1tXXYmTNnzmjp0qWSpMWLF+vixYuybTsrAwMAMuP6SCeZTMrv96eu/X6/2tvb73smLy9P+fn56u3t1bRp04adi0ajikajkqRIJKKSkpIR/wLGC3bhYBcOduFgFyM3pt+0DYfDikQiikQievfdd8fy1g80duFgFw524WAXjpHswjX4Pp9PiUQidZ1IJOTz+e575vbt2+rv79fUqVMzHgoAMPpcgx8MBhWLxdTT06OhoSG1tLQoFAoNO/PEE0/ou+++kySdPn1ajz32mDweT1YGBgBkxvUZfl5enioqKlRXVyfLslReXq7S0lI1NjYqGAwqFArp6aef1v79+7V+/XoVFBRo48aNrjcOh8OjMf+4wC4c7MLBLhzswjGSXXhs/jsNABiBn7QFAEMQfAAwRFpvrTASvC2Dw20Xx44d08mTJ5WXl6dp06Zp3bp1mjFjRm6GzTK3Xfzl9OnT2r17t7Zv365gMDi2Q46RdHbR0tKiL7/8Uh6PRw899JCqqqrGftAx4LaLeDyuAwcOqK+vT5Zlac2aNVq4cGFuhs2igwcP6uzZsyosLNSuXbvuet22bTU0NOjcuXOaPHmyKisr9cgjj7h/YjuLbt++bb/++uv2jRs37MHBQfutt96yr1+/PuzM8ePH7UOHDtm2bds//PCDvXv37myOlDPp7OKnn36yBwYGbNu27RMnThi9C9u27f7+fvv999+3a2tr7Y6OjhxMmn3p7KK7u9t+++237d7eXtu2bfvmzZu5GDXr0tnFxx9/bJ84ccK2bdu+fv26XVlZmYtRs+7SpUv21atX7TfffPOer//44492XV2dbVmW/fPPP9s1NTVpfd6sPtLhbRkc6exi3rx5mjx5siRpzpw5SiaTuRg169LZhSQ1NjbqhRde0MSJE3Mw5dhIZxcnT57UM888o4KCAklSYWFhLkbNunR24fF41N/fL0nq7+/X9OnTczFq1j366KOp3+97OXPmjJ566il5PB7NnTtXfX19+vXXX10/b1aDf6+3ZfjfiN3vbRnGm3R28XdNTU1asGDBGEw29tLZRWdnp+Lx+Lj85/rfpbOL7u5uxWIxbd68We+9957a2trGeMqxkc4uVq1ape+//16vvvqqtm/froqKirEe84GQTCYVCARS1249+QvftH0AnTp1Sp2dnXr++edzPUpOWJalw4cP66WXXsr1KA8Ey7IUi8W0ZcsWVVVV6dChQ+rr68v1WDnR3NyspUuX6uOPP1ZNTY327dsny7JyPda/RlaDz9syONLZhSRduHBBR44cUXV19bh9lOG2i4GBAV2/fl3btm3Ta6+9pvb2du3YsUNXr17NxbhZle7fkVAoJK/Xq5kzZ2rWrFmKxWJjPWrWpbOLpqYmLVmyRJI0d+5cDQ4OjssnAm58Pp/i8Xjq+n49+V9ZDT5vy+BIZxfXrl3TJ598ourq6nH7nFZy30V+fr7q6+t14MABHThwQHPmzFF1dfW4/F866fy5WLRokS5duiRJunXrlmKxmIqKinIxblals4tAIKCLFy9Kkrq6ujQ4OHjXu/KaIBQK6dSpU7JtW1euXFF+fn5a38/I+k/anj17Vp999lnqbRlWrlw57G0Z/vzzT+3fv1/Xrl1LvS3DePzDLLnv4oMPPtAvv/yi//znP5L++4f7nXfeye3QWeK2i7/bunWrXnzxxXEZfMl9F7Zt6/Dhw2pra9OECRO0cuVKPfnkk7keOyvcdtHV1aVDhw5pYGBAkrR27VrNnz8/x1OPvr179+ry5cvq7e1VYWGhVq9eraGhIUnS8uXLZdu26uvrdf78eU2aNEmVlZVp/f3grRUAwBB80xYADEHwAcAQBB8ADEHwAcAQBB8ADEHwAcAQBB8ADPF/YdptXyNMLgIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# validation set\n",
    "predictions = model.predict(val_X, batch_size=batch_size)\n",
    "predictions = np.argmax(predictions, axis= 1)\n",
    "actuals = np.argmax(val_Y, axis= 1)\n",
    "\n",
    "print(classification_report(actuals, predictions))\n",
    "\n",
    "# Plot the losses and accuracies\n",
    "N = epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"],\n",
    "label= \"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"],\n",
    "label= \"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"accuracy\"],\n",
    "label= \"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"],\n",
    "label= \"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Brain Dataset\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss / Accuracy\")\n",
    "plt.legend(loc= \"lower left\")\n",
    "#plt.savefig(\"plot.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd2d1e2-6acf-4e3c-b3eb-141f2050c8a8",
   "metadata": {},
   "source": [
    "## Test Set (Out of Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f615f-e39b-48c8-920c-8d13953ed741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of sample data\n",
    "predictions = model.predict(test_X, batch_size=batch_size)\n",
    "predictions = np.argmax(predictions, axis= 1)\n",
    "actuals = np.argmax(test_Y, axis= 1)\n",
    "\n",
    "print(classification_report(actuals, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12afa3e-2e24-44b4-a2bd-f17a40617d51",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e7966-c52e-4b54-b0f3-412a51f6da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('outputs/model_01.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
